# global configs
Global:
  checkpoints: null
  pretrained_model: null
  output_dir: "./abalation/standard_baseline_BNNeck_laststride1_LS_warmup_correct_augv1"
  device: "gpu"
  save_interval: 110
  eval_during_train: True
  eval_interval: 1
  epochs: 100
  print_batch_step: 20
  use_visualdl: False
  eval_mode: "retrieval"
  retrieval_feature_from: "features" # 'backbone' or 'features'
  re_ranking: False
  use_dali: False
  # used for static mode and model export
  image_shape: [3, 224, 224]
  save_inference_dir: "./inference_standard_baseline_BNNeck_laststride1_LS_warmup_augv1"

# AMP:
#   scale_loss: 65536
#   use_dynamic_loss_scaling: True
#   # O1: mixed fp16
#   level: O1

# model architecture
Arch:
  name: RecModel
  infer_output_key: backbone
  infer_add_softmax: False

  Backbone:
    name: PPLCNet_x2_5
    use_ssld: True
    pretrained: True
    last_stride: 1
    class_num: &feat_dim 512
  # BackboneStopLayer:
  # name: "flatten"
  Neck:
    name: BNNeck
    num_features: *feat_dim
    weight_attr:
      initializer:
        name: Constant
        value: 1.0
    bias_attr:
      initializer:
        name: Constant
        value: 0.0
      learning_rate: 1.0e-20 # NOTE: Temporarily set lr small enough to freeze the bias to zero
  Head:
    name: "FC"
    embedding_size: *feat_dim
    class_num: &class_num 10000
    weight_attr:
      initializer:
        name: Normal
        std: 0.001
    bias_attr: False

# loss function config for traing/eval process
Loss:
  Train:
    - CELoss:
        weight: 1.0
        epsilon: 0.1
    - TripletLossV2:
        weight: 1.0
        margin: 0.3
        normalize_feature: False
        feature_from: "backbone"
    # - CenterLoss:
    #     weight: 0.0005
    #     num_classes: *class_num
    #     feat_dim: *feat_dim
    #     feature_from: "backbone"
  Eval:
    - CELoss:
        weight: 1.0

Optimizer:
  - Momentum:
      scope: RecModel
      momentum: 0.9
      lr:
        name: Cosine
        learning_rate: 0.04 # 1gpux256bs
        warmup_epoch: 5
      regularizer:
        name: "L2"
        coeff: 0.00001
  # - SGD:
  #     scope: CenterLoss
  #     lr:
  #       name: Constant
  #       learning_rate: 1000.0 # NOTE: set to ori_lr*(1/centerloss_weight) to avoid manually scaling centers' gradidents.

# data loader for train and eval
DataLoader:
  Train:
    dataset:
      name: "ImageNetDataset"
      image_root: /workspace/dongshuilong/dataset/ppshitu_traindata/
      cls_label_path: ./dataset/train_reg_all_data_small.txt
      relabel: True
      transform_ops:
        - DecodeImage:
            to_rgb: True
            channel_first: False
        - RandCropImage:
            size: 224
        - RandFlipImage:
            flip_code: 1
        - NormalizeImage:
            scale: 1.0/255.0
            mean: [0.485, 0.456, 0.406]
            std: [0.229, 0.224, 0.225]
            order: ""
    sampler:
      name: PKSampler
      batch_size: 256
      sample_per_id: 4
      drop_last: False
      shuffle: True
      sample_method: "id_avg_prob"
    loader:
      num_workers: 4
      use_shared_memory: True

  Eval:
    Query:
      dataset:
        name: VeriWild
        image_root: /workspace/dongshuilong/dataset/ppshitu_rec_test_white_data/
        cls_label_path: /workspace/dongshuilong/dataset/ppshitu_rec_test_white_data/query_clean.txt
        transform_ops:
          - DecodeImage:
              to_rgb: True
              channel_first: False
          - ResizeImage:
              size: 224
          - NormalizeImage:
              scale: 0.00392157
              mean: [0.485, 0.456, 0.406]
              std: [0.229, 0.224, 0.225]
              order: ""
      sampler:
        name: DistributedBatchSampler
        batch_size: 64
        drop_last: False
        shuffle: False
      loader:
        num_workers: 4
        use_shared_memory: True

    Gallery:
      dataset:
        name: VeriWild
        image_root: /workspace/dongshuilong/dataset/ppshitu_rec_test_white_data/
        cls_label_path: /workspace/dongshuilong/dataset/ppshitu_rec_test_white_data/gallery_clean.txt
        transform_ops:
          - DecodeImage:
              to_rgb: True
              channel_first: False
          - ResizeImage:
              size: 224
          - NormalizeImage:
              scale: 0.00392157
              mean: [0.485, 0.456, 0.406]
              std: [0.229, 0.224, 0.225]
              order: ""
      sampler:
        name: DistributedBatchSampler
        batch_size: 64
        drop_last: False
        shuffle: False
      loader:
        num_workers: 4
        use_shared_memory: True

Metric:
  Eval:
    - Recallk:
        topk: [1, 5]
    - mAP: {}
